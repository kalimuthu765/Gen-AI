{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gosaitos/GEN-AI/blob/main/Resume_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DhGR0A_JRK-"
   },
   "outputs": [],
   "source": [
    "#!pip install PyPDF2\n",
    "#!pip install -U langchain-community\n",
    "#!pip install faiss-cpu\n",
    "#!pip install keybert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wg3ZYVYaIIYb",
    "outputId": "fa1e261c-7050-4eec-98a2-b5666d2e401a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ **Extracted Resume Key Points:**\n",
      "Name: Yunlong Jiao\n",
      "Machine Learning\n",
      "Email: yljiao.ustc@gmail.com\n",
      "Phone: Not Found\n",
      "Skills: Python, AI, NLP, Docker, SQL, DevOps, C++\n",
      "Experience: Not Found\n",
      "Education: PhD in the field of ML\n",
      "\n",
      "ðŸ“Œ **Resume Match Score:** 42.3 %\n",
      "\n",
      "ðŸ“Œ **Improvement Suggestions:**\n",
      " - Missing Skills:\n",
      "    - 'NLP': Natural Language Processing (as the job description requires this skill)\n",
      "\n",
      "- Resume Formatting:\n",
      "    - 'Phone': Add a professional phone number under the 'Contact Information' section\n",
      "\n",
      "- Additional Experience Needed:\n",
      "    - 'Experience': Include past experiences, internships, or projects that involve data science, ML, and NLP to demonstrate practical application of skills\n",
      "\n",
      "- Certifications to Add:\n",
      "    - 'Google Professional Certificate - Machine Learning with TensorFlow' or 'IBM AI Engineering Professional Certificate' to show advanced knowledge in ML and related technologies\n",
      "\n",
      "- Keywords to Include:\n",
      "    - 'Machine Learning', 'Python', 'NLP', 'Data Science', 'Data Analysis', 'Model Training', 'Predictive Modeling', 'TensorFlow', 'Scikit-learn' (these keywords are commonly used in data science roles, and are relevant to the job description)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# OpenRouter API Key (Replace with actual key)\n",
    "OPENROUTER_API_KEY = \"\"\n",
    "\n",
    "# HuggingFace Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# OpenRouter API Configuration\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"your-website.com\"\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                extracted_text = page.extract_text()\n",
    "                if extracted_text:\n",
    "                    text += extracted_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting text from PDF:\", e)\n",
    "    return text.strip() if text else \"No text extracted\"\n",
    "\n",
    "def extract_key_points(resume_text):\n",
    "    \"\"\"Extracts key points (Name, Email, Phone, Skills, Experience, and Education) from the resume.\"\"\"\n",
    "    doc = nlp(resume_text)\n",
    "\n",
    "    # Extract Name\n",
    "    name = next((ent.text for ent in doc.ents if ent.label_ == \"PERSON\"), \"Not Found\")\n",
    "\n",
    "    # Extract Email\n",
    "    email = re.findall(r\"[\\w.-]+@[\\w.-]+\", resume_text)\n",
    "    email = email[0] if email else \"Not Found\"\n",
    "\n",
    "    # Extract Phone Number\n",
    "    phone = re.findall(r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\", resume_text)\n",
    "    phone = phone[0] if phone else \"Not Found\"\n",
    "\n",
    "    # Extract Skills (Dynamic Matching)\n",
    "    common_skills = [\n",
    "        \"python\", \"java\", \"c++\", \"javascript\", \"react\", \"angular\", \"node.js\", \"django\", \"flask\",\n",
    "        \"tensorflow\", \"pytorch\", \"machine learning\", \"deep learning\", \"nlp\", \"data science\",\n",
    "        \"big data\", \"sql\", \"mongodb\", \"postgresql\", \"aws\", \"azure\", \"google cloud\", \"docker\",\n",
    "        \"kubernetes\", \"devops\", \"linux\", \"cybersecurity\", \"ai\", \"computer vision\", \"data analysis\"\n",
    "    ]\n",
    "    skills = [token.text for token in doc if token.text.lower() in common_skills]\n",
    "    skills_str = \", \".join(set(skills)) if skills else \"Not Found\"\n",
    "\n",
    "    # Extract Experience (Flexible Matching)\n",
    "    experience_matches = re.findall(r\"(\\d+)\\s*(?:year|years)\\s*of experience\", resume_text, re.IGNORECASE)\n",
    "    experience_str = f\"{experience_matches[0]} years\" if experience_matches else \"Not Found\"\n",
    "\n",
    "    # Extract Education (Flexible Matching)\n",
    "    education_matches = re.findall(r\"(Bachelor|Master|PhD)[^\\n,]*\\sin\\s*([\\w\\s]+)\", resume_text, re.IGNORECASE)\n",
    "    education_str = f\"{education_matches[0][0]} in {education_matches[0][1]}\" if education_matches else \"Not Found\"\n",
    "\n",
    "    return {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Skills\": skills_str,\n",
    "        \"Experience\": experience_str,\n",
    "        \"Education\": education_str\n",
    "    }\n",
    "\n",
    "def match_resume_with_job(resume_text, job_description):\n",
    "    \"\"\"Calculates the match score between resume and job description using embeddings.\"\"\"\n",
    "    # Convert text to embeddings\n",
    "    resume_embedding = embedding_model.embed_documents([resume_text])[0]\n",
    "    job_embedding = embedding_model.embed_documents([job_description])[0]\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    resume_embedding = np.array(resume_embedding).reshape(1, -1)\n",
    "    job_embedding = np.array(job_embedding).reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(resume_embedding, job_embedding.T) / (np.linalg.norm(resume_embedding) * np.linalg.norm(job_embedding))\n",
    "\n",
    "    match_score = similarity[0][0] * 100  # Convert to percentage\n",
    "    return round(match_score, 2)\n",
    "\n",
    "def suggest_improvements(resume_text, job_description):\n",
    "    \"\"\"Uses OpenRouter API to suggest resume improvements in key-value format.\"\"\"\n",
    "    max_resume_length = 800  # Adjust to avoid token limit errors\n",
    "    max_job_length = 500\n",
    "\n",
    "    resume_text = resume_text[:max_resume_length]\n",
    "    job_description = job_description[:max_job_length]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/mistral-7b-instruct\",  # Use \"openai/gpt-4\" if you want GPT-4\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that provides resume improvement suggestions in key-value format.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Resume Key Points:\n",
    "            {extract_key_points(resume_text)}\n",
    "\n",
    "            Job Description:\n",
    "            {job_description}\n",
    "\n",
    "            Provide key-value pairs suggesting improvements in these categories:\n",
    "            - Missing Skills\n",
    "            - Resume Formatting\n",
    "            - Additional Experience Needed\n",
    "            - Certifications to Add\n",
    "            - Keywords to Include\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        \"max_tokens\": 300  # Ensures response is within API limits\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "    response_data = response.json()\n",
    "\n",
    "    if \"choices\" in response_data:\n",
    "        return response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return {\"Error\": \"Unable to generate suggestions.\"}\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "file_path = \"/content/resume.pdf\"  # Change this to actual file path\n",
    "job_description = \"Data Scientist role requiring Python, NLP, and Machine Learning.\"\n",
    "\n",
    "resume_text = extract_text_from_pdf(file_path)\n",
    "if resume_text != \"No text extracted\":\n",
    "    key_points = extract_key_points(resume_text)\n",
    "    match_score = match_resume_with_job(resume_text, job_description)\n",
    "    suggestions = suggest_improvements(resume_text, job_description)\n",
    "\n",
    "    print(\"\\nðŸ“Œ **Extracted Resume Key Points:**\")\n",
    "    for key, value in key_points.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ **Resume Match Score:**\", match_score, \"%\")\n",
    "\n",
    "    print(\"\\nðŸ“Œ **Improvement Suggestions:**\")\n",
    "    print(suggestions)\n",
    "\n",
    "else:\n",
    "    print(\"No text found in the provided resume file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eyvUmihORX0",
    "outputId": "6a1c3729-4989-4a26-aedd-639a69f705eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Hello! As an AI, I don't have feelings, but I'm functioning as expected. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your OpenRouter API key\n",
    "API_KEY = \"\"\n",
    "\n",
    "# OpenRouter API Endpoint\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"your-website.com\"  # Replace with your domain if needed\n",
    "}\n",
    "\n",
    "# Request Payload\n",
    "data = {\n",
    "    \"model\": \"openai/gpt-4\",  # Choose your desired model\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "# Send Request\n",
    "response = requests.post(API_URL, headers=headers, json=data)\n",
    "\n",
    "# Check Response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Response:\", result[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrO98ddwOsRr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPg4KtkNY5PDCkNczwwXbbL",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
