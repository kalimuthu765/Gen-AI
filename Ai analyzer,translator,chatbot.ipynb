{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "1ZOzxL1k7wWw",
    "outputId": "c3862edd-a7ff-424d-9d5a-fc713f1891c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-a2a4d0fb690e>:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://48876529f8a55a5590.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://48876529f8a55a5590.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Set API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Chatbot function\n",
    "conversation_history = [SystemMessage(content=\"You are a helpful assistant.\")]\n",
    "\n",
    "def chatbot(user_input):\n",
    "    global conversation_history\n",
    "    conversation_history.append(HumanMessage(content=user_input))\n",
    "\n",
    "    response = chat(conversation_history)\n",
    "\n",
    "    conversation_history.append(AIMessage(content=response.content))\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"AI Chatbot\",\n",
    "    description=\"Chat with an AI-powered assistant.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "jBKFlXbEHLDY",
    "outputId": "1c9d6392-028c-4c64-fa04-b4cff00c93d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://6779d74902a46edc12.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6779d74902a46edc12.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Set API Key for OpenRouter\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Summarization function\n",
    "def summarize_news(article_text):\n",
    "    prompt = (\n",
    "        \"Summarize the following news article in a concise and informative way:\\n\\n\"\n",
    "        f\"{article_text}\\n\\n\"\n",
    "        \"Provide a short summary highlighting the main points.\"\n",
    "    )\n",
    "\n",
    "    response = chat([SystemMessage(content=\"You are an AI news summarizer.\"), HumanMessage(content=prompt)])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=summarize_news,\n",
    "    inputs=gr.Textbox(lines=10, placeholder=\"Paste your news article here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üì∞ AI News Summarizer\",\n",
    "    description=\"Paste a news article, and this AI will generate a concise summary for you.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "unxpgtRZJy8b",
    "outputId": "938bede0-0944-41de-dd40-4680d1268246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://000b10766b1136486f.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://000b10766b1136486f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Set API Key for OpenRouter\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Translation function\n",
    "def translate_text(text, target_language):\n",
    "    prompt = (\n",
    "        f\"Translate the following text to {target_language}:\\n\\n\"\n",
    "        f\"Text: {text}\\n\\n\"\n",
    "        \"Provide the translation in the specified language.\"\n",
    "    )\n",
    "\n",
    "    response = chat([SystemMessage(content=\"You are a multilingual AI translator.\"), HumanMessage(content=prompt)])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=translate_text,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=3, placeholder=\"Enter text to translate...\"),\n",
    "        gr.Dropdown(choices=[\"French\", \"Spanish\", \"German\", \"Chinese\", \"Hindi\", \"Japanese\", \"Arabic\", \"Russian\"], label=\"Target Language\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"üåç AI Multilingual Translator\",\n",
    "    description=\"Enter text and select a language to translate in real-time!\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "HSxZjV1lLQo6",
    "outputId": "68761c08-a6fd-4e01-d5a6-2d7c1e9d04c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://6d3ebf279be54ddcf9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6d3ebf279be54ddcf9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Set API Key for OpenRouter\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Resume Analysis Function\n",
    "def analyze_resume(resume_text):\n",
    "    prompt = (\n",
    "        \"Analyze the following resume text and provide feedback on improvements:\\n\\n\"\n",
    "        f\"{resume_text}\\n\\n\"\n",
    "        \"Suggestions should include formatting, skills to highlight, and overall structure.\"\n",
    "    )\n",
    "\n",
    "    response = chat([\n",
    "        SystemMessage(content=\"You are an expert HR professional providing resume analysis.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=analyze_resume,\n",
    "    inputs=gr.Textbox(lines=10, placeholder=\"Paste resume text here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üìÑ AI Resume Analyzer\",\n",
    "    description=\"Paste your resume and get AI-powered suggestions for improvement!\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "73Chi1KCPhYE",
    "outputId": "fded3f50-0009-4e4c-b687-703f2e2c8b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://785744bf6513c6d7f7.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://785744bf6513c6d7f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Set API Key for OpenRouter\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text(image):\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text.strip()\n",
    "\n",
    "# Resume Analysis Function\n",
    "def analyze_resume(image):\n",
    "    # Extract text from image\n",
    "    resume_text = extract_text(image)\n",
    "\n",
    "    if not resume_text:\n",
    "        return \"Could not extract text. Please upload a clearer resume image.\"\n",
    "\n",
    "    # AI-based analysis\n",
    "    prompt = (\n",
    "        \"Analyze the following resume text and provide feedback on improvements:\\n\\n\"\n",
    "        f\"{resume_text}\\n\\n\"\n",
    "        \"Suggestions should include formatting, skills to highlight, and overall structure.\"\n",
    "    )\n",
    "\n",
    "    response = chat([\n",
    "        SystemMessage(content=\"You are an expert HR professional providing resume analysis.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=analyze_resume,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üìÑ AI Resume Analyzer (Image-Based)\",\n",
    "    description=\"Upload an image of your resume and get AI-powered feedback!\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "eO1BpvXsRJTi",
    "outputId": "b9070d03-875c-4fad-eeb5-dbcc98231103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/langchain_community/llms/openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/langchain_community/llms/openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://a88b96c9b673e7cdef.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a88b96c9b673e7cdef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Set OpenRouter API Key\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize the AI Model\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
    "\n",
    "def analyze_symptoms(symptoms):\n",
    "    \"\"\"AI-based symptom analysis for possible diagnosis\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    A patient reports the following symptoms: {symptoms}.\n",
    "    Based on common medical knowledge, suggest possible diagnoses and provide advice.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get AI response\n",
    "    response = llm(prompt)\n",
    "    return response\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=analyze_symptoms,\n",
    "    inputs=gr.Textbox(label=\"Enter your symptoms\"),\n",
    "    outputs=gr.Textbox(label=\"Possible Diagnoses\"),\n",
    "    title=\"ü©∫ AI Symptom Analyzer\",\n",
    "    description=\"Enter your symptoms and get AI-powered suggestions for possible conditions.\",\n",
    ")\n",
    "\n",
    "# Launch App\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQMmBflpGHDd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
